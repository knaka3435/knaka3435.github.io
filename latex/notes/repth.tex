\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{lindrew}[formal]
\usepackage{import}
\title{Representation Theory}
\author{Kenji Nakagawa}
\date{August 2020}

\begin{document}

\maketitle
\tableofcontents

\section*{Introduction}
Initial section is based off of Steinberg's ``Theory of Finite Groups'', which gives a brief overview of some of the traditional results of representation theory. The middle section follows Sagan's ``The Symmetric Group,'' while the modular theory uses more of Serre's ``Linear Representations of Finite Groups'' and Alperin's ``Local Representation Theory.'' Or at least, tentatively.

\subsection{Roadmap}
Begin by developing some of the classical results through Steinberg and by the first two sections of Serre.

Focus on characteristic $0$ representations of the symmetric group through Sagan.

Finally, try to work through the modular portion of Serre to develop modular representation theory. Alperin might be entirely unncessary.

Try to finish off with Nakayama or The Symmetric Group by James-Kerber

\section{Notation and Linear Algebra Recap}
We make a few notations explicit. The complex inner product conjugates the first argument, that is, $\langle u, v \rangle = \sum_i \overline{u}_iv_i$. Additionally, we have $V$ be a finite vector space, unless specified otherwise.


\begin{definition}
The \vocab{minimal polynomial} associated to a matrix, $A$ is the smallest monic polynomial, $m$, such that $m(A)=0$.
\end{definition}
The minimal polynomial contains no repeated roots if and only if the matrix is diagonalizable. Note that $J_1(2)$, the $2 \times 2$ Jordan block, has minimal polynomial $(x-1)^2$

As for some abstract nonsense, we have $\Hom(V,W)$ represents a morphism between objects $V,W$, which in the case of both being vector spaces, is a linear transformation. We also have that $\End(V) = \Hom(V,V)$, which for linear transformations, corresponds to square matrices.

\subsection{Algebras, Modules, etc.}
A \vocab{module} is essentially a vector space, but the field condition is weakened to some ring.

An \vocab{algebra} (over a field) is a vector space that has a bilinear product. For example, Number fields are an example, as well as square matrices. These are both associative, while there are also nonassociative algebras, such as vectors of $\RR^3$ with the cross product.

\section{Classical Results}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%    Maschke's Theorem     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Maschke's Theorem}
\begin{definition}
A \vocab{representation} of a group is a homomorphism $\phi : G \to GL(V)$ for some vector space $V$. A representation is \vocab{irreducible} if the only $G$-invariant subspaces are trivial.
\end{definition}

Some easy examples of representations is $\rho : G \to \QQ$, where $g \mapsto 1$ for all $g \in G$, and the operation is multiplication. This is referred to as the trivial representation, and is irreducible, as it has degree $1$, and there are no nontrivial subspaces.

A particularly important representation that comes up a lot is called the (left) \vocab{regular} representation, which has standard basis $e_{g_i}$, and has $\rho_{reg}(g) e_{g_i} = e_{gg_i}$. This has the notable feature that all  $\rho_{reg} (g)$ are permutation matrices, and arise naturally from thinking about the group action of $G$ on itself (or equivalently, Cayley's theorem). Interestingly enough, over $\CC$, this also contains every other irreducible representation, with multiplicity equal to their degree.

We also have a few notions that are in a similar vein: A representation is \vocab{completely reducible} if it factorizes into the direct sum of several irreducible representations (and with the proper basis, this corresponds to a block diagonal matrix), and we say that a representation is \vocab{decomposable} if we can break it down into two smaller representations.

Another common one is that of equivalence, which is two representations of $G$, $\rho, \phi$  are considered equivalent, denoted, $\rho \sim \phi$ if there exists some isomorphism, $T$, from their corresponding vector spaces such that $T\rho=\phi T$. Unsurprisingly, if something that is true about $\rho$, such as reducibility, is also true about $\phi$. These proofs mainly consist of definitions and the fact that $T$ is an isomorphism, and aren't too interesting so far.

We wish to prove the following iconic theorem:

\begin{theorem}
(Maschke's theorem) Every finite group is the direct sum of irreducible representations if the characteristic of the field does not divide the order of the group.
\end{theorem}
\begin{proof}

In the characteristic $0$ case, we employ the ``averaging" trick:

Let's suppose that we have some inner product, $\langle \cdot , \cdot \rangle$ defined on the vector space $V$ over $F$ (of characteristic $p$). We define $\langle v, w \rangle' := \frac{1}{|G|} \sum_{g \in G} \langle \rho(g)v , \rho(g)w \rangle,$ which we expect to be an inner product that makes our representations unitary. We have that the linearity of $\langle \cdot, \cdot \rangle '$ drops out easily from the definition, as does the fact that $\langle v,v \rangle' = 0 \iff v = 0$, and positive otherwise. Furthermore, we have that $\langle \rho(h)v, \rho(h)w \rangle' = \langle v, w \rangle'$ due to the fact that $$\sum_{g \in G} \langle \rho(g)\rho(h)v, \rho(g)\rho(h)w \rangle = \sum_{g \in G} \langle \rho(gh)v, \rho(gh)w \rangle = \sum_{g \in G} \langle \rho(g)v, \rho(g)v\rangle,$$ as it just permutes the summands.

In other words, every representation is equivalent to a unitary one, and so we now prove the theorem.

Suppose $\rho$ is not irreducible, and has $W$ as a proper $G$-invariant subspace, then, we wish to prove that $W^\perp$ is also $G$-invariant. Let $w \in W, \ w' \in W^\perp$, then $$\langle w, \rho(g)w' \rangle = \langle \rho(g^{-1})w, w' \rangle  = 0,$$ where the last equality follows since $W$ is $G$-invariant and consequently $\rho(g^{-1})w \in W$. And then, we can continue this argument on both $W$ and $W^\perp,$ until we're just left with irreducible representations.

In the case of characteristic $p>0$ fields, we must be more careful, as the notion of an inner product isn't nearly as strong, and so instead, we use projections, which still captures all of the essential information.

Suppose that we have that $P$ is a projection from $V$ onto our proper $G$-invariant subspace, $W$, then for all $g \in G$, we have that $\rho(g)P\rho(g^{-1})$ is another projection onto $W$, as this is just a change of basis. Using the same averaging trick, we want to look at $$P' = \frac{1}{|G|} \sum_{g \in G} \rho(g)P\rho(g^{-1}).$$ (Note: this is where the characteristic condition plays in) From similar reasoning to before, we have that $P'$ is a projection onto $W$. Additionally, we have that for any $g$, $\rho(g)P'=P'\rho(g)$ from the following:
$$ \sum_{h \in G} \rho(gh)P\rho(h^{-1}) = \sum_{h' \in G} \rho(h')P\rho(h'^{-1}g),$$ where $h' = gh$. All that's left is to prove that the kernel of $P'$ is also $G$-invariant, or rather that if $v \in \ker P'$, then $\rho(g)v \in \ker P'$ as well, but $P'\rho(g)v = \rho(g)P'v=0$, and so, we are done.

\end{proof}

These conditions are sharp.
\begin{example}
The infinite group $\ZZ$ under addition has the representation $$\rho : \ZZ \to \GL_2\left(\RR\right) \quad \textrm{defined by} \quad \rho(n) = \begin{pmatrix} 1 & n \\ 0 & 1 \end{pmatrix}.$$
\end{example}

This is easily verified to be a homomorphism, as they are all powers of $\rho(1)$. Now, we have that $\begin{pmatrix} 1  \\ 0 \end{pmatrix}$ is an eigenvector of each of the $\rho(n)$, and so, it is $G$-invariant, however, there is no other common eigenvector, and so it is not possible to split up $\rho$ into two degree one irreducible representations.

\begin{example}
The finite group $\ZZ/p\ZZ$ under addition, where $\rho  : \ZZ/p\ZZ \to \GL_2(\FF_p)$ and $\rho(n) = \begin{pmatrix} 1 & n \\ 0 & 1 \end{pmatrix}$ isn't irreducible and cannot be decomposed.
\end{example}

Essentially, in both cases, the obstruction was that these are the powers of Jordan blocks, which lacks the needed number of eigenvalues to be the direct sum of degree one irreducible representations, but has a fixed subspace.

\begin{note}
Modular representation theory is hard.
\end{note}
Oftentimes the same theorems over fields of positive characteristic are intractable to put alongside that of those with characteristic $0$, as $\FF_q$ has a rather nasty algebraic closure, so it's not nearly as nice to consider an infinite degree extension, as compared to our familiar degree two extension. Also the general fact that we have to be more careful about $0$ is a large thorn in our side. As a result, from here on out until much later, we will usually work over $\CC$ (and occasionally $\RR$), as modular representation theory is an entirely different beast. 

However, we will still take out a step ladder, place it underneath a tree, and try to use a broom to hit some of the low-lying fruit when it presents itself.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     Character Theory     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Character Theory}

A rather interesting result is that you can discard a large amount of the information of the group, and instead focus on the \vocab{characters} of the representations in order to extract more information about the group. For example, the monster group of order about $8 \times 10^{53}$ has a character table that is a far more reasonable $194 \times 194$.

But first, we need to look at representations a bit more closely.

\begin{definition}
Suppose that $\rho : G \to \GL(V)$ and $\phi : G \to \GL(W)$ (here $W$ is not necessarily some subspace). An \vocab{intertwining transformation} is a linear transformation $T : V \to W$ such that for all $g \in G$, $T\phi(g) = \rho(g)T$. In some other sources, this is also referred to as a homomorphism (of representations), and is denoted as $\Hom_G(\rho, \phi)$.
\end{definition}

We have that $\Hom_G(\rho, \phi)$ is in fact a subspace of $\Hom(V,W)$, and that for any $T$ of $\Hom_G(\rho,\phi)$, we have that both $\ker T$ and $\Im T$ are $G$-invariant subspaces. The $\ker T$ fact follows easily from commutativity, and the $\Im T$ fact from considering some $w = Tv$, and then $\rho(g)w = T\phi(g)v \in \Im T$.

It turns out that with vector fields whose underlying field is algebraically closed, say, $\overline{\FF}$, these are particularly nice.
\begin{theorem}
(Schur's Lemma) Let $\rho$ and $\phi$ be irreducible representations of $G$ over vector spaces over $\overline{\FF}$. Then:
\begin{itemize}
    \item If $\rho \not\sim \phi,$ then $\Hom_G(\rho,\phi) = 0$, and the only intertwining transformation is $0$.
    \item If $\rho = \phi,$ then any element of $\Hom_G(\rho,\phi)$ is of the form $T=\lambda I$, where $\lambda \in \CC$.
\end{itemize}
\end{theorem}

\begin{proof}

Suppose that $T \neq 0$, then since the only possible invariant subspaces are the trivial ones, and so $\ker T = 0$ and $\Im T = W$, otherwise $T = 0$. And so, $T$ is invertible.

If $T \neq 0$, we have that $\rho \sim \phi$, and so we are already done with the case that $\rho \not\sim \phi$, as $\Hom_G(\rho,\phi) = 0$. Now, if $\rho = \phi$, we have that there exists some $\lambda$ which is an eigenvalue of $T$, and so $T-\lambda I $ is not invertible, and in fact must be $0$, and so we are done. 

We can say something that is a bit stronger, which is that if $\rho \sim \phi$, then $\dim \Hom_G(\rho, \phi) = 1$, which can be seen from the fact that $\rho = S \phi S^{-1}$, and applying Schur's Lemma.
\end{proof}

\begin{corollary}
The irreducible representations of an abelian group have degree one, and any completely reducible representation $\rho$ is equivalent to some $\phi$ that is diagonal.

Consequently, for any $A \in \GL_n(\CC)$ of finite order $k$, $A$ is diagonalizable and if $A^k = I$, then all of the eigenvalues of $A$ are $k$-th roots of unity.
\end{corollary}
\begin{proof}
This first statement follows nicely from the fact that the number of irreducible characters is equal to the number of conjugacy classes. Alternatively, note that $\rho(g)\rho(h) = \rho(h)\rho(g)$, and so $\rho(g)$ is an intertwining transformation, so $\rho(g) = \lambda_g I$. Now, since $\CC v$ is going to be a $G$-invariant subspace for any nonzero $v$, we have that $V = \CC v$ and is invarient. The back half of the statement then follows from the fact that with the right basis, the $\rho(g_i)$ become a block matrix with all $1 \times 1$ blocks, since every irreducible representation has degree one.

Now, we have a fairly natural representation given by $\rho : \ZZ_k \to \GL_n(\CC)$, where $\rho(a) = A^a$, and we get for free that $A$ is diagonalizable, and the eigenvalue fact is simple enough.
\end{proof}

\begin{definition}
(Group algebra) Define $L(G) = \CC^G = \{ f \ | \ f : G \to \CC \}$ with the usual linearity, and inner product $$\langle f_1, f_2 \rangle = \frac{1}{|G|} \sum_{g \in G} \overline{f_1(g)}f_2(g).$$
\end{definition}

Also, for a bit of notation, we have $\rho_{ij}(g) = (\rho(g))_{ij}$ be the $ij$th entry of the matrix corresponding to $\rho(g)$. And in this section, we have representations $\rho, \ \phi$ which map to $\GL(V), \ \GL(W)$, respectively, and we let $P : \Hom(V,W) \to \Hom(V,W)$ send elements of $T \in \Hom(V,W)$ to $$\frac{1}{|G|} \sum_{g \in G} \phi(g^{-1})T\rho(g)$$.

\begin{lemma}
For any $T \in \Hom(V,W)$, we have that\ldots
\begin{enumerate}[label=(\alph*)]
    \item $P(T) \in \Hom_G(\rho,\phi)$
    \item If $T \in \Hom_G(V,W),$ then $P(T)=T$.
    \item $P : \Hom(V,W) \to \Hom_G(\rho,\phi)$ is a surjective linear map.
\end{enumerate}
\end{lemma}

\begin{proof}

For (a), similarly to an argument in the proof of Mashke's theorem, we have that $P(T)\rho(h)$ can be rewritten using a change of variables, which is equivalent to $\rho(h)P(T).$

For (b), we have that $\phi(g^{-1})T\rho(g)=\phi(g^{-1})\phi(g)T=T$, and $\frac{1}{|G|} |G|T = T$. Linearity is simple enough to check, and (b) implies (c).

\end{proof}

Note that as a result, we have that if $\rho \not\sim \phi$, and $T : V \to W$, then $P(T) = 0$, since $P(T) \in \Hom_G(\rho,\phi),$ and if $\rho \sim \phi,$ then $P(T) = \frac{\tr (T)}{\deg \rho} I.$ This last fact follows from the fact that $\tr P(T)= \tr \left( \lambda I \right) = \lambda \deg \phi$, which implies that $P(T) = \frac{\tr P(T)}{\deg \rho} = \frac{\tr T}{\deg \rho}$ (due to summing similar matrices). 

We can also consider $P$ as a linear operator on $\Hom(V,W)$, and we want to compute the matrix of $P$ with respect to the standard basis $E_{ij}$ (whose only nonzero entry is a $1$ in the $ij$th entry). Note that for 3 appropriately sized matrices, $(AE_{ki}B)_{\ell j} = a_{\ell k}b_{ij}$.

\begin{lemma}

If $\rho, \ \phi$ are representations to $U_n(\CC)$ and $U_m(\CC),$ respectively, then $P(E_{ki})_{\ell j} = \langle \phi_{k\ell}, \rho_{ij} \rangle$.

\end{lemma}
\begin{proof}
This is a routine calculation,
\begin{align*}
    (P(E_{ki}))_{\ell j} &= \frac{1}{|G|} \sum_{g \in G} (\phi(g^{-1})E_{ki}\rho(g))_{\ell j} \\
    &= \frac{1}{|G|} \sum_{g \in G} \overline{\phi_{kl}}(g)\rho_{ij}(g) \\
    &= \langle \phi_{k\ell}, \rho_{ij}\rangle
\end{align*}
\end{proof}

\begin{note}
Currently, this is horribly unintuitive. We can think of $P$ as being a $m \times m$ block matrix whose blocks are themselves $n \times n$ matrices.
\end{note}





\subsection{Fourier Analysis on Finite Groups}

\subsection{Burnside's pq theorem}

\subsection{Induced Representations}

\section{A Brief Interlude}
In other words, looking at modules and algebras because I have no idea what I'm doing.

\section{Characteristic 0: Symmetric Group}


\section{Modular Representations}

\section{Characteristic p: Symmetric Group}



\end{document}
